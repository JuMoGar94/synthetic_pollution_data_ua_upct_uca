{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T21:59:32.220839Z",
     "iopub.status.busy": "2025-02-10T21:59:32.210690Z",
     "iopub.status.idle": "2025-02-10T21:59:39.152735Z",
     "shell.execute_reply": "2025-02-10T21:59:39.155038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version:  1.18.5\n",
      "Pandas version:  1.3.4\n",
      "MatPlotLib version:  3.3.2\n",
      "TensorFlow version:  2.4.1\n",
      "Keras version:  2.4.0\n",
      "\n",
      "CPU times: user 6.56 s, sys: 8.29 s, total: 14.9 s\n",
      "Wall time: 6.89 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Import libraries and show its versions\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import sys\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import glob\n",
    "from glob import glob\n",
    "import math\n",
    "from math import sqrt, log, prod\n",
    "import collections\n",
    "from collections import OrderedDict\n",
    "import pickle\n",
    "from pickle import dump\n",
    "import warnings\n",
    "\n",
    "try:\n",
    "    import numpy as np; print('NumPy version: ', np.__version__)\n",
    "    from numpy import array, asarray, delete, append, concatenate\n",
    "except:\n",
    "    !{sys.executable} -m pip install numpy==1.19.5\n",
    "    import numpy as np; print('NumPy version: ', np.__version__)\n",
    "    from numpy import array, asarray, delete, append, concatenate\n",
    "\n",
    "try:\n",
    "    import pandas as pd; print('Pandas version: ', pd.__version__)\n",
    "    from pandas import read_csv, DataFrame, concat\n",
    "except:\n",
    "    !{sys.executable} -m pip install pandas\n",
    "    import pandas as pd; print('Pandas version: ', pd.__version__)\n",
    "    from pandas import read_csv, DataFrame, concat\n",
    "    \n",
    "try:\n",
    "    import matplotlib as mpl; print('MatPlotLib version: ', mpl.__version__)\n",
    "    from matplotlib import pyplot as plt\n",
    "except:\n",
    "    !{sys.executable} -m pip install matplotlib\n",
    "    import matplotlib as mpl; print('MatPlotLib version: ', mpl.__version__)\n",
    "    from matplotlib import pyplot as plt\n",
    "    \n",
    "try:\n",
    "    import tensorflow as tf; print('TensorFlow version: ', tf.__version__)\n",
    "    import tensorflow.keras as keras; print('Keras version: ', keras.__version__)\n",
    "    from tensorflow.keras import backend as K\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Dense\n",
    "    from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "except:\n",
    "    !{sys.executable} -m pip install tensorflow\n",
    "    import tensorflow as tf; print('TensorFlow version: ', tf.__version__)\n",
    "    import tensorflow.keras as keras; print('Keras version: ', keras.__version__)\n",
    "    from tensorflow.keras import backend as K\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import TimeDistributed, Conv1D, MaxPooling1D, Flatten, LSTM, Dense\n",
    "    from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "# Configurations\n",
    "np.set_printoptions(linewidth=1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "#warnings.filterwarnings('ignore')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define functions #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T21:59:39.169116Z",
     "iopub.status.busy": "2025-02-10T21:59:39.168162Z",
     "iopub.status.idle": "2025-02-10T21:59:39.220983Z",
     "shell.execute_reply": "2025-02-10T21:59:39.220274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 629 µs, sys: 0 ns, total: 629 µs\n",
      "Wall time: 607 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Date parser\n",
    "def custom_date_parser(date):\n",
    "    try:\n",
    "        return pd.to_datetime(date, format='%Y-%m-%d %H:%M:%S')\n",
    "    except ValueError:\n",
    "        return pd.to_datetime(date, format='%d/%m/%Y %H:%M')\n",
    "\n",
    "def create_univariate_timeseries_dataset(dataset, look_back):\n",
    "    dataset = asarray(dataset)\n",
    "    X, y = [], []\n",
    "    for i in range(len(dataset) - look_back):\n",
    "        X.append(dataset[i:(i + look_back), 0])\n",
    "        y.append(dataset[i + look_back, 0])\n",
    "    return array(X), array(y)\n",
    "\n",
    "def create_multivariate_timeseries_dataset(data, columns, n_in=1, n_out=1, dropnan=True):\n",
    "    n_features = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # Input sequence (t-n, ..., t-2, t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [f'{columns[j]} (t-{i})' for j in range(n_features)]\n",
    "    # Output sequence (t, t+1, ..., t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [f'{columns[j]} (t)' for j in range(n_features)]\n",
    "        else:\n",
    "            names += [f'{columns[j]} (t+{i})' for j in range(n_features)]\n",
    "    # Concatenate sequences\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # Drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "def update_fixed_size_array(array, new_value, *, axis=0):\n",
    "    internal_array = array.copy()\n",
    "    internal_array = delete(internal_array, 0, axis=1)\n",
    "    internal_array = append(internal_array, new_value, axis=axis)\n",
    "    return internal_array\n",
    "\n",
    "def min_max_scaler(array, *, min_limit=None, max_limit=None, min_range=0, max_range=1):\n",
    "    min_limit = min_limit if min_limit is not None else min(array)\n",
    "    max_limit = max_limit if max_limit is not None else max(array)\n",
    "    return [((x - min_limit) / (max_limit - min_limit)) * (max_range - min_range) + min_range\n",
    "            if max_limit - min_limit != 0 else float(0)\n",
    "            for x in array]\n",
    "\n",
    "def min_max_inverse_scaler(array, *, min_limit=None, max_limit=None, min_range=0, max_range=1):\n",
    "    min_limit = min_limit if min_limit is not None else min(array)\n",
    "    max_limit = max_limit if max_limit is not None else max(array)\n",
    "    if max_limit - min_limit == 0:\n",
    "        return [float(min_limit) for _ in array]\n",
    "    else:\n",
    "        scale = (max_range - min_range) / (max_limit - min_limit)\n",
    "        return [(x - (min_range - min_limit * scale)) / scale for x in array]\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_true)\n",
    "    n = len(y_pred)\n",
    "    try:\n",
    "        x_bar = sum(y_pred) / n\n",
    "        y_bar = sum(y_true) / n\n",
    "    except ZeroDivisionError:\n",
    "        return float('nan')\n",
    "    try:\n",
    "        x_std = sqrt(sum([(xi - x_bar) ** 2 for xi in y_pred]) / (n - 1))\n",
    "        y_std = sqrt(sum([(yi - y_bar) ** 2 for yi in y_true]) / (n - 1))\n",
    "    except ZeroDivisionError:\n",
    "        return float('nan')\n",
    "    try:\n",
    "        zx = [(xi - x_bar) / x_std for xi in y_pred]\n",
    "    except ZeroDivisionError:\n",
    "        return float('nan')\n",
    "    try:\n",
    "        zy = [(yi - y_bar) / y_std for yi in y_true]\n",
    "    except ZeroDivisionError:\n",
    "        return float('nan')\n",
    "    try:\n",
    "        r = sum(zxi * zyi for zxi, zyi in zip(zx, zy)) / (n - 1)\n",
    "    except ZeroDivisionError:\n",
    "        return float('nan')\n",
    "    return r ** 2\n",
    "\n",
    "def rmse(y_true, y_pred, squared=False):\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_true)\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(y_true)):\n",
    "        prediction_error = y_pred[i] - y_true[i]\n",
    "        sum_error += (prediction_error ** 2)\n",
    "    try:\n",
    "        mean_error = sum_error / float(len(y_true))\n",
    "    except ZeroDivisionError:\n",
    "        return float('nan')\n",
    "    return mean_error if squared else sqrt(mean_error)\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_true)\n",
    "    sum_error = 0.0\n",
    "    for i in range(len(y_true)):\n",
    "        sum_error += abs(y_pred[i] - y_true[i])\n",
    "    try:\n",
    "        return sum_error / float(len(y_true))\n",
    "    except ZeroDivisionError:\n",
    "        return float('nan')\n",
    "\n",
    "def sem(y_true, y_pred):\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_true)\n",
    "    abs_err = []\n",
    "    norm_err = []\n",
    "    for i in range(len(y_true)):\n",
    "        abs_err.append(abs(y_pred[i] - y_true[i]))\n",
    "    for i in range(len(y_true)):\n",
    "        norm_err.append(abs_err[i] / sum(abs_err) if sum(abs_err) != 0 else 0)\n",
    "    return float(-sum([x * log(x) if x != 0 else 0 for x in norm_err]))\n",
    "\n",
    "def aem(y_true, y_pred):\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_true)\n",
    "    abs_err = []\n",
    "    norm_err = []\n",
    "    for i in range(len(y_true)):\n",
    "        abs_err.append(abs(y_pred[i] - y_true[i]))\n",
    "    for i in range(len(y_true)):\n",
    "        norm_err.append(abs_err[i] / sum(abs_err) if sum(abs_err) != 0 else 0)\n",
    "    return float(prod([2 - x ** x for x in norm_err]))\n",
    "\n",
    "def aicbic(y_true, y_pred):\n",
    "    y_pred = list(y_pred)\n",
    "    y_true = list(y_true)\n",
    "    abs_err = []\n",
    "    for i in range(len(y_true)):\n",
    "        abs_err.append(abs(y_pred[i] - y_true[i]))\n",
    "    return float(log(sum([x * x for x in abs_err])) if sum([x * x for x in abs_err]) != 0 else '-inf')\n",
    "\n",
    "def mape(actual, pred):\n",
    "    #actual, pred = np.array(actual), np.array(pred)\n",
    "    #return np.mean(np.abs((actual - pred) / (actual if actual.all() > 0 else 1e-10))) * 100\n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    denominator = np.where(actual != 0, actual, 1)  # Avoid division by zero\n",
    "    return np.mean(np.abs((actual - pred) / denominator)) * 100\n",
    "\n",
    "def cvrmse(actual, pred):\n",
    "    #return rmse(actual, pred)/((np.mean(actual) if np.mean(actual) > 0 else 1e-10) * 100)\n",
    "    return rmse(actual, pred) / np.mean(actual) * 100\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def K_mse(y_true, y_pred):\n",
    "    _y_true = y_true[:, 0]\n",
    "    _y_pred = y_pred[:, 0]\n",
    "    return K.mean(K.square(_y_pred - _y_true), axis=-1)\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def K_rmse(y_true, y_pred):\n",
    "    _y_true = y_true[:, 0]\n",
    "    _y_pred = y_pred[:, 0]\n",
    "    return K.sqrt(K.mean(K.square(_y_pred - _y_true), axis=-1))\n",
    "\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def K_entropy(y_true, y_pred):\n",
    "    return -y_pred * K.log(y_true + 1e-10)\n",
    "\n",
    "class LossHistory(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.lr = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.lr.append(K.eval(self.model.optimizer.lr))\n",
    "\n",
    "def scheduler(epoch, lr):\n",
    "    # Step decay\n",
    "    #drop = 0.5\n",
    "    #epochs_drop = 100\n",
    "    #return lr if (epoch == 0 or epoch % epochs_drop != 0) else lr*drop\n",
    "\n",
    "    # Step continuous decay\n",
    "    #drop = 0.5\n",
    "    #return lr*drop\n",
    "    \n",
    "    # Exponential decay\n",
    "    drop = 0.1\n",
    "    return lr * tf.math.exp(-drop)\n",
    "\n",
    "class ReduceLROnPlateauRestoreBestWeights(ReduceLROnPlateau):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            #logging.warning('Reduce LR on plateau conditioned on metric `%s` '\n",
    "            #                'which is not available. Available metrics are: %s',\n",
    "            #                 self.monitor, ','.join(list(logs.keys())))\n",
    "            pass\n",
    "        if self.monitor_op(current - self.min_delta, self.best): # New best\n",
    "            self.best_weights = self.model.get_weights() \n",
    "        if not self.monitor_op(current - self.min_delta, self.best): # Not new best\n",
    "            if not self.in_cooldown(): # And we're not in cooldown\n",
    "                if self.wait+1 >= self.patience: # Going to reduce lr\n",
    "                    # Reset best weights so far\n",
    "                    #print(\"Backtracking to best model before reducting LR\")\n",
    "                    self.model.set_weights(self.best_weights)\n",
    "        super().on_epoch_end(epoch, logs) # Actually reduce LR\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define parameters #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T21:59:39.241574Z",
     "iopub.status.busy": "2025-02-10T21:59:39.239420Z",
     "iopub.status.idle": "2025-02-10T21:59:39.247021Z",
     "shell.execute_reply": "2025-02-10T21:59:39.245747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 263 µs, sys: 0 ns, total: 263 µs\n",
      "Wall time: 269 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Global variables\n",
    "multivariate_variables = {\n",
    "    'Dataset_example': [\n",
    "        'Variable_example',\n",
    "    ],\n",
    "}\n",
    "steps_to_forecast = {\n",
    "    'Dataset_example': [12 * 1, 24 * 1],\n",
    "}\n",
    "\n",
    "# Dataset variables\n",
    "datasets = {}\n",
    "synth_datasets = {}\n",
    "synth_smooth_datasets = {}\n",
    "real_synth_datasets = {}\n",
    "normalization_parameters = {\n",
    "    'Variable_example': {\n",
    "        'min_limit': 0,\n",
    "        'max_limit': 1.5,\n",
    "        'min_range': 0,\n",
    "        'max_range': 1\n",
    "    },\n",
    "}\n",
    "look_back = {\n",
    "    'Dataset_example': 24 * 1,\n",
    "}\n",
    "validation_sizes = {\n",
    "    'Dataset_example': 24 * 1,\n",
    "}\n",
    "test_sizes = {\n",
    "    'Dataset_example': 24 * 1,\n",
    "}\n",
    "days_to_validate = 1\n",
    "test_type = 'real_synth_shuffled'\n",
    "\n",
    "# Model variables\n",
    "model_parameters = {\n",
    "    'cnn_model': {\n",
    "        'filters': 64,\n",
    "        'kernel_size': 2,\n",
    "        'strides': 1,\n",
    "        'activation': 'tanh'\n",
    "    },\n",
    "    'lstm_model': {\n",
    "        'units': 70,\n",
    "        'activation': 'tanh',\n",
    "    },\n",
    "    'fit': {\n",
    "        'batch_size': 30 * 24 * 4,\n",
    "        'epochs': 15000,\n",
    "        'verbose': 0\n",
    "    },\n",
    "    'predict': {\n",
    "        'batch_size': 30 * 24 * 4,\n",
    "        'verbose': 0\n",
    "    },\n",
    "    'compile': {\n",
    "        'optimizer': 'adam',\n",
    "        'loss': 'mse',\n",
    "        #'metrics': [K_rmse]\n",
    "    },\n",
    "    'backend': {\n",
    "        'lr': 0.003\n",
    "    },\n",
    "    #'dropout': {\n",
    "    #    'rate': 0\n",
    "    #}\n",
    "}\n",
    "\n",
    "# Metric variables\n",
    "available_metrics = {\n",
    "    'r2': r2,\n",
    "    'rmse': rmse,\n",
    "    'mae': mae,\n",
    "    'sem': sem,\n",
    "    'aem': aem,\n",
    "    'aicbic': aicbic,\n",
    "    'mape': mape,\n",
    "    'cvrmse': cvrmse\n",
    "}\n",
    "\n",
    "# Output variables\n",
    "output = {}\n",
    "synth_output = {}\n",
    "synth_smooth_output = {}\n",
    "real_synth_output = {}\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read datasets #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T21:59:39.273386Z",
     "iopub.status.busy": "2025-02-10T21:59:39.268381Z",
     "iopub.status.idle": "2025-02-10T21:59:42.303842Z",
     "shell.execute_reply": "2025-02-10T21:59:42.305086Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- 60_MADRID -------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 421 entries, 2023-09-13 11:00:00 to 2023-09-30 23:00:00\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   CO          421 non-null    float64\n",
      " 1   O3          421 non-null    float64\n",
      " 2   PM10        421 non-null    float64\n",
      " 3   PM2.5       421 non-null    float64\n",
      " 4   SO2         421 non-null    float64\n",
      " 5   SpeedWind   421 non-null    float64\n",
      " 6   DirecWind   421 non-null    int64  \n",
      " 7   Temp        421 non-null    float64\n",
      " 8   Humid       421 non-null    int64  \n",
      " 9   Precip      421 non-null    float64\n",
      " 10  Car         421 non-null    int64  \n",
      " 11  Motorcycle  421 non-null    int64  \n",
      " 12  Bus         421 non-null    int64  \n",
      " 13  Truck       421 non-null    int64  \n",
      "dtypes: float64(8), int64(6)\n",
      "memory usage: 49.3 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87600 entries, 0 to 87599\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   CO          87600 non-null  float64\n",
      " 1   O3          87600 non-null  float64\n",
      " 2   PM10        87600 non-null  float64\n",
      " 3   PM2.5       87600 non-null  float64\n",
      " 4   SO2         87600 non-null  float64\n",
      " 5   SpeedWind   87600 non-null  float64\n",
      " 6   DirecWind   85872 non-null  float64\n",
      " 7   Temp        87600 non-null  float64\n",
      " 8   Humid       87600 non-null  float64\n",
      " 9   Precip      87600 non-null  float64\n",
      " 10  Car         85467 non-null  float64\n",
      " 11  Motorcycle  87600 non-null  float64\n",
      " 12  Bus         86081 non-null  float64\n",
      " 13  Truck       85862 non-null  float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 10.0 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 88021 entries, 0 to 2023-09-30 23:00:00\n",
      "Data columns (total 14 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   CO          88021 non-null  float64\n",
      " 1   O3          88021 non-null  float64\n",
      " 2   PM10        88021 non-null  float64\n",
      " 3   PM2.5       88021 non-null  float64\n",
      " 4   SO2         88021 non-null  float64\n",
      " 5   SpeedWind   88021 non-null  float64\n",
      " 6   DirecWind   86293 non-null  float64\n",
      " 7   Temp        88021 non-null  float64\n",
      " 8   Humid       88021 non-null  float64\n",
      " 9   Precip      88021 non-null  float64\n",
      " 10  Car         85888 non-null  float64\n",
      " 11  Motorcycle  88021 non-null  float64\n",
      " 12  Bus         86502 non-null  float64\n",
      " 13  Truck       86283 non-null  float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 10.1+ MB\n",
      "None\n",
      "------------------------------------- 60_BILBAO -------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 350 entries, 2023-09-18 20:00:00 to 2023-10-03 09:00:00\n",
      "Data columns (total 23 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Benceno      350 non-null    float64\n",
      " 1   CO           350 non-null    float64\n",
      " 2   CO 8h        350 non-null    float64\n",
      " 3   Etilbenceno  350 non-null    float64\n",
      " 4   NO           350 non-null    float64\n",
      " 5   NO2          350 non-null    float64\n",
      " 6   NOX          350 non-null    float64\n",
      " 7   O3           350 non-null    float64\n",
      " 8   O3 8h        350 non-null    float64\n",
      " 9   Ortoxileno   350 non-null    float64\n",
      " 10  PM10         350 non-null    float64\n",
      " 11  PM2.5        350 non-null    float64\n",
      " 12  SO2          350 non-null    float64\n",
      " 13  Tolueno      350 non-null    float64\n",
      " 14  DirecWind    350 non-null    float64\n",
      " 15  Humid        350 non-null    float64\n",
      " 16  Precip       350 non-null    float64\n",
      " 17  Temp         350 non-null    float64\n",
      " 18  SpeedWind    350 non-null    float64\n",
      " 19  Car          350 non-null    int64  \n",
      " 20  Motorcycle   350 non-null    int64  \n",
      " 21  Bus          350 non-null    int64  \n",
      " 22  Truck        350 non-null    int64  \n",
      "dtypes: float64(19), int64(4)\n",
      "memory usage: 65.6 KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 87600 entries, 0 to 87599\n",
      "Data columns (total 23 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Benceno      87600 non-null  float64\n",
      " 1   CO           87600 non-null  float64\n",
      " 2   CO 8h        87600 non-null  float64\n",
      " 3   Etilbenceno  87600 non-null  float64\n",
      " 4   NO           87600 non-null  float64\n",
      " 5   NO2          87600 non-null  float64\n",
      " 6   NOX          87600 non-null  float64\n",
      " 7   O3           87600 non-null  float64\n",
      " 8   O3 8h        87600 non-null  float64\n",
      " 9   Ortoxileno   87600 non-null  float64\n",
      " 10  PM10         87600 non-null  float64\n",
      " 11  PM2.5        87600 non-null  float64\n",
      " 12  SO2          87600 non-null  float64\n",
      " 13  Tolueno      87600 non-null  float64\n",
      " 14  DirecWind    86091 non-null  float64\n",
      " 15  Humid        87600 non-null  float64\n",
      " 16  Precip       87600 non-null  float64\n",
      " 17  Temp         87600 non-null  float64\n",
      " 18  SpeedWind    87600 non-null  float64\n",
      " 19  Car          85690 non-null  float64\n",
      " 20  Motorcycle   87600 non-null  float64\n",
      " 21  Bus          86526 non-null  float64\n",
      " 22  Truck        86316 non-null  float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 16.0 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 87950 entries, 0 to 2023-10-03 09:00:00\n",
      "Data columns (total 23 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Benceno      87950 non-null  float64\n",
      " 1   CO           87950 non-null  float64\n",
      " 2   CO 8h        87950 non-null  float64\n",
      " 3   Etilbenceno  87950 non-null  float64\n",
      " 4   NO           87950 non-null  float64\n",
      " 5   NO2          87950 non-null  float64\n",
      " 6   NOX          87950 non-null  float64\n",
      " 7   O3           87950 non-null  float64\n",
      " 8   O3 8h        87950 non-null  float64\n",
      " 9   Ortoxileno   87950 non-null  float64\n",
      " 10  PM10         87950 non-null  float64\n",
      " 11  PM2.5        87950 non-null  float64\n",
      " 12  SO2          87950 non-null  float64\n",
      " 13  Tolueno      87950 non-null  float64\n",
      " 14  DirecWind    86441 non-null  float64\n",
      " 15  Humid        87950 non-null  float64\n",
      " 16  Precip       87950 non-null  float64\n",
      " 17  Temp         87950 non-null  float64\n",
      " 18  SpeedWind    87950 non-null  float64\n",
      " 19  Car          86040 non-null  float64\n",
      " 20  Motorcycle   87950 non-null  float64\n",
      " 21  Bus          86876 non-null  float64\n",
      " 22  Truck        86666 non-null  float64\n",
      "dtypes: float64(23)\n",
      "memory usage: 16.1+ MB\n",
      "None\n",
      "\n",
      "CPU times: user 2.57 s, sys: 200 ms, total: 2.77 s\n",
      "Wall time: 3.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Iterate over all possible train datasets\n",
    "for file in glob('./datasets/*.csv'):\n",
    "    \n",
    "    # Print a header\n",
    "    print('-' * 37, Path(file).stem.upper(), '-' * 37)\n",
    "    \n",
    "    # Read a dataset\n",
    "    datasets[Path(file).stem] = read_csv(file, parse_dates={'Fecha_Hora': ['Fecha', 'Hora']}, date_parser=custom_date_parser, index_col='Fecha_Hora')\n",
    "    \n",
    "    # Update parameters\n",
    "    steps_to_forecast[Path(file).stem] = [12 * 1, 24 * 1]\n",
    "    \n",
    "    # Update parameters\n",
    "    look_back[Path(file).stem] = max(steps_to_forecast[Path(file).stem]) * 1\n",
    "    \n",
    "    # Update parameters\n",
    "    validation_sizes[Path(file).stem] = max(steps_to_forecast[Path(file).stem]) * 1\n",
    "    \n",
    "    # Update parameters\n",
    "    test_sizes[Path(file).stem] = max(steps_to_forecast[Path(file).stem]) * 1\n",
    "    \n",
    "    # Update parameters\n",
    "    multivariate_variables[Path(file).stem] = [col for col in datasets[Path(file).stem].columns if col not in ['Fecha', 'Hora', 'Fecha_Hora']]\n",
    "    \n",
    "    # Select variables\n",
    "    datasets[Path(file).stem] = datasets[Path(file).stem][multivariate_variables[Path(file).stem]]\n",
    "\n",
    "    # Iterpolate datasets\n",
    "    datasets[Path(file).stem] = datasets[Path(file).stem].interpolate('linear')\n",
    "    \n",
    "    # Update parameters\n",
    "    for col in datasets[Path(file).stem].columns:\n",
    "        col_min = datasets[Path(file).stem][col].min() * 0.9\n",
    "        col_max = datasets[Path(file).stem][col].max() * 1.1\n",
    "\n",
    "        # Si la columna ya existe en normalization_parameters, aplicar condiciones de actualización\n",
    "        if col in normalization_parameters:\n",
    "            normalization_parameters[col]['min_limit'] = min(normalization_parameters[col]['min_limit'], col_min)\n",
    "            normalization_parameters[col]['max_limit'] = max(normalization_parameters[col]['max_limit'], col_max)\n",
    "        else:\n",
    "            # Si no existe, añadir la columna con los valores calculados\n",
    "            normalization_parameters[col] = {\n",
    "                'min_limit': col_min,\n",
    "                'max_limit': col_max,\n",
    "                'min_range': 0,\n",
    "                'max_range': 1\n",
    "            }\n",
    "    \n",
    "    # Print dataset info\n",
    "    print(datasets[Path(file).stem].info())\n",
    "    \n",
    "    # Synth dataset\n",
    "    synth_datasets[Path(file).stem] = read_csv(f'./datasets/synth/{Path(file).stem}_synth.csv', sep=';', parse_dates=True, index_col=[0])\n",
    "    synth_datasets[Path(file).stem] = synth_datasets[Path(file).stem][multivariate_variables[Path(file).stem]]\n",
    "    print(synth_datasets[Path(file).stem].info())\n",
    "    \n",
    "    # Real synth dataset\n",
    "    real_synth_datasets[Path(file).stem] = concat([synth_datasets[Path(file).stem], datasets[Path(file).stem]])\n",
    "    print(real_synth_datasets[Path(file).stem].info())\n",
    "\n",
    "\"\"\"\n",
    "# Order datasets\n",
    "key_order = {k:v for v,k in enumerate([\n",
    "    '60_Bilbao',\n",
    "    '60_Madrid',\n",
    "])}\n",
    "ordered_dict = OrderedDict(sorted(datasets.items(), key=lambda i:key_order.get(i[0])))\n",
    "datasets = ordered_dict\n",
    "\"\"\"\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate model #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T21:59:42.324756Z",
     "iopub.status.busy": "2025-02-10T21:59:42.312424Z",
     "iopub.status.idle": "2025-02-10T23:08:19.997209Z",
     "shell.execute_reply": "2025-02-10T23:08:19.998555Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------- 60_MADRID -------------------------------------\n",
      "----------------- Day 1 -----------------\n",
      "------- 12 -------\n",
      "METRICS:\n",
      "CO\n",
      "R2: 0.9084483814429354\n",
      "RMSE: 0.017545416243890367\n",
      "MAE: 0.012407914930954616\n",
      "SEM: 2.1162658403583476\n",
      "AEM: 5.738579969566664\n",
      "AICBIC: -5.601018441949418\n",
      "MAPE: 4.408351330960274\n",
      "CVRMSE: 5.848472081296791\n",
      "\n",
      "O3\n",
      "R2: 0.9519311945601693\n",
      "RMSE: 2.932635315605105\n",
      "MAE: 2.5893988007472637\n",
      "SEM: 2.3320709430534383\n",
      "AEM: 6.794289016410075\n",
      "AICBIC: 4.636709537607539\n",
      "MAPE: 8.016818768893605\n",
      "CVRMSE: 8.736025764318065\n",
      "\n",
      "PM10\n",
      "R2: 0.32262883448324114\n",
      "RMSE: 4.35454654824571\n",
      "MAE: 2.8918255813992944\n",
      "SEM: 1.9635577828285253\n",
      "AEM: 4.986268487920807\n",
      "AICBIC: 5.427347615350731\n",
      "MAPE: 16.01300453770636\n",
      "CVRMSE: 24.928780239498376\n",
      "\n",
      "PM2.5\n",
      "R2: 0.621407234916847\n",
      "RMSE: 2.3178955984377443\n",
      "MAE: 1.5593493018349005\n",
      "SEM: 1.9893745468823956\n",
      "AEM: 5.101459402221628\n",
      "AICBIC: 4.166226058593419\n",
      "MAPE: 17.56082025620957\n",
      "CVRMSE: 24.587621817682148\n",
      "\n",
      "SO2\n",
      "R2: nan\n",
      "RMSE: 0.44296464394861046\n",
      "MAE: 0.3703902380191723\n",
      "SEM: 2.241526598399388\n",
      "AEM: 6.228331733188321\n",
      "AICBIC: 0.8563760045444415\n",
      "MAPE: 37.03902380191723\n",
      "CVRMSE: 44.29646439486105\n",
      "\n",
      "SPEEDWIND\n",
      "R2: 0.8849356487912179\n",
      "RMSE: 0.12135844534756977\n",
      "MAE: 0.09762987154101337\n",
      "SEM: 2.2066831541628664\n",
      "AEM: 6.065840590441139\n",
      "AICBIC: -1.7331068587679028\n",
      "MAPE: 17.801117141057514\n",
      "CVRMSE: 22.57831541350135\n",
      "\n",
      "DIRECWIND\n",
      "R2: 0.00888988369803139\n",
      "RMSE: 18.149656228207416\n",
      "MAE: 14.053787333983928\n",
      "SEM: 2.15464806772586\n",
      "AEM: 5.792549726566288\n",
      "AICBIC: 8.282209889661704\n",
      "MAPE: 240.52345380960674\n",
      "CVRMSE: 130.41669146017304\n",
      "\n",
      "TEMP\n",
      "R2: 0.9417495246510639\n",
      "RMSE: 0.8918558399087593\n",
      "MAE: 0.6388583158825836\n",
      "SEM: 2.107485023821257\n",
      "AEM: 5.660484365241848\n",
      "AICBIC: 2.256005101957572\n",
      "MAPE: 3.295554473724285\n",
      "CVRMSE: 4.875749466471577\n",
      "\n",
      "HUMID\n",
      "R2: 0.957770287250568\n",
      "RMSE: 1.9974053605817912\n",
      "MAE: 1.58773171901703\n",
      "SEM: 2.180945670985395\n",
      "AEM: 5.917565094698925\n",
      "AICBIC: 3.868604686994211\n",
      "MAPE: 2.3290289453375403\n",
      "CVRMSE: 2.908842758128822\n",
      "\n",
      "PRECIP\n",
      "R2: nan\n",
      "RMSE: 0.06134392423613392\n",
      "MAE: 0.04591087715816685\n",
      "SEM: 2.0889769773839952\n",
      "AEM: 5.448949150032208\n",
      "AICBIC: -3.0976116445825936\n",
      "MAPE: 4.591087715816685\n",
      "CVRMSE: inf\n",
      "\n",
      "CAR\n",
      "R2: 0.8079621053488838\n",
      "RMSE: 112.56984465722053\n",
      "MAE: 94.10739787903924\n",
      "SEM: 2.253451553994469\n",
      "AEM: 6.313917815353116\n",
      "AICBIC: 11.9320543905874\n",
      "MAPE: 16.430529432775522\n",
      "CVRMSE: 18.42135736924378\n",
      "\n",
      "MOTORCYCLE\n",
      "R2: 0.6254085238824345\n",
      "RMSE: 14.39113521070033\n",
      "MAE: 10.818416075160107\n",
      "SEM: 2.107990030859907\n",
      "AEM: 5.559233089521243\n",
      "AICBIC: 7.818131463084113\n",
      "MAPE: 33.39291585178065\n",
      "CVRMSE: 43.39035741919698\n",
      "\n",
      "BUS\n",
      "R2: 0.5781148206152308\n",
      "RMSE: 19.917855229717187\n",
      "MAE: 13.24849301499004\n",
      "SEM: 1.9808809639879708\n",
      "AEM: 5.063800827992804\n",
      "AICBIC: 8.46813980412561\n",
      "MAPE: 20.68811487257623\n",
      "CVRMSE: 28.31922544509553\n",
      "\n",
      "TRUCK\n",
      "R2: 0.6898254174191101\n",
      "RMSE: 41.061345716543904\n",
      "MAE: 24.09902575653202\n",
      "SEM: 1.8635682614311304\n",
      "AEM: 4.712810587523989\n",
      "AICBIC: 9.915041020679846\n",
      "MAPE: 41.32804410666861\n",
      "CVRMSE: 78.46117015900109\n",
      "\n",
      "------- 24 -------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<timed exec>:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "<timed exec>:152: RuntimeWarning: divide by zero encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METRICS:\n",
      "CO\n",
      "R2: 0.7953700565683754\n",
      "RMSE: 0.08215799945221003\n",
      "MAE: 0.049663002156859516\n",
      "SEM: 2.576752869485997\n",
      "AEM: 9.107139824202896\n",
      "AICBIC: -1.820168295795062\n",
      "MAPE: 13.497339095988256\n",
      "CVRMSE: 23.614275291653186\n",
      "\n",
      "O3\n",
      "R2: 0.8745756337058661\n",
      "RMSE: 22.66399380159405\n",
      "MAE: 16.108772814936106\n",
      "SEM: 2.6736120655628888\n",
      "AEM: 9.721979630825025\n",
      "AICBIC: 9.41960880842178\n",
      "MAPE: 22.220935627161683\n",
      "CVRMSE: 37.437511986573476\n",
      "\n",
      "PM10\n",
      "R2: 0.7492615307154882\n",
      "RMSE: 5.56667211291053\n",
      "MAE: 4.180139693222749\n",
      "SEM: 2.798319780500412\n",
      "AEM: 11.11324152234109\n",
      "AICBIC: 6.61164864859051\n",
      "MAPE: 17.75007355949295\n",
      "CVRMSE: 25.292000862503063\n",
      "\n",
      "PM2.5\n",
      "R2: 0.6703268003438443\n",
      "RMSE: 3.903025192939702\n",
      "MAE: 2.916563801894585\n",
      "SEM: 2.7895257823639583\n",
      "AEM: 11.010043062364172\n",
      "AICBIC: 5.901557716229091\n",
      "MAPE: 22.61849954332443\n",
      "CVRMSE: 32.882002503046195\n",
      "\n",
      "SO2\n",
      "R2: 0.12947706620073443\n",
      "RMSE: 0.38999081967311544\n",
      "MAE: 0.32608562951209036\n",
      "SEM: 2.959326577674251\n",
      "AEM: 13.141233646710134\n",
      "AICBIC: 1.2947896714775404\n",
      "MAPE: 31.09215489338386\n",
      "CVRMSE: 37.439118688619075\n",
      "\n",
      "SPEEDWIND\n",
      "R2: 0.6993245608641641\n",
      "RMSE: 0.18076581032992975\n",
      "MAE: 0.1463157801354149\n",
      "SEM: 2.9105108340084205\n",
      "AEM: 12.486262981980646\n",
      "AICBIC: -0.24305207177924748\n",
      "MAPE: 29.660431900360116\n",
      "CVRMSE: 33.526889087467644\n",
      "\n",
      "DIRECWIND\n",
      "R2: 0.03976989312240134\n",
      "RMSE: 56.75117402691829\n",
      "MAE: 37.563522889294354\n",
      "SEM: 2.6366107474635276\n",
      "AEM: 9.510544387813695\n",
      "AICBIC: 11.255406518040996\n",
      "MAPE: 613.89200587978\n",
      "CVRMSE: 324.29242301096167\n",
      "\n",
      "TEMP\n",
      "R2: 0.9034116809145551\n",
      "RMSE: 3.9361076509722093\n",
      "MAE: 2.971541696706165\n",
      "SEM: 2.751343938488993\n",
      "AEM: 10.495760832809596\n",
      "AICBIC: 5.918438488677192\n",
      "MAPE: 11.322178554207023\n",
      "CVRMSE: 17.358798901751747\n",
      "\n",
      "HUMID\n",
      "R2: 0.86010982885185\n",
      "RMSE: 5.391561376939491\n",
      "MAE: 3.5192678093910215\n",
      "SEM: 2.6473057444977015\n",
      "AEM: 9.670483874646447\n",
      "AICBIC: 6.547723876936721\n",
      "MAPE: 7.293696463233847\n",
      "CVRMSE: 9.196693180280581\n",
      "\n",
      "PRECIP\n",
      "R2: nan\n",
      "RMSE: 0.08471528680761095\n",
      "MAE: 0.06492474374521409\n",
      "SEM: 2.8270777869890265\n",
      "AEM: 11.445605099310088\n",
      "AICBIC: -1.7588645932901172\n",
      "MAPE: 6.492474374521408\n",
      "CVRMSE: inf\n",
      "\n",
      "CAR\n",
      "R2: 0.4683973811923952\n",
      "RMSE: 312.3711643507604\n",
      "MAE: 197.70226970203217\n",
      "SEM: 2.6467646422177773\n",
      "AEM: 9.756801273017539\n",
      "AICBIC: 14.666438050529079\n",
      "MAPE: 25.765746792056692\n",
      "CVRMSE: 36.93603953499655\n",
      "\n",
      "MOTORCYCLE\n",
      "R2: 0.19428759493271083\n",
      "RMSE: 34.80342200140074\n",
      "MAE: 25.938165344049537\n",
      "SEM: 2.785016399270321\n",
      "AEM: 10.964624250120284\n",
      "AICBIC: 10.277485260987154\n",
      "MAPE: 102.76772947332668\n",
      "CVRMSE: 106.9503364959818\n",
      "\n",
      "BUS\n",
      "R2: 0.4920013872249987\n",
      "RMSE: 37.8947443242143\n",
      "MAE: 27.725074161635717\n",
      "SEM: 2.7496731658474105\n",
      "AEM: 10.55969339688278\n",
      "AICBIC: 10.447678690924317\n",
      "MAPE: 39.57020007219826\n",
      "CVRMSE: 49.29397635670153\n",
      "\n",
      "TRUCK\n",
      "R2: 0.7072145044179794\n",
      "RMSE: 62.70240757055274\n",
      "MAE: 40.51409445795774\n",
      "SEM: 2.5621350321393286\n",
      "AEM: 8.769747570318144\n",
      "AICBIC: 11.454853520660167\n",
      "MAPE: 56.5434948604985\n",
      "CVRMSE: 105.75247938814236\n",
      "\n",
      "------------------------------------- 60_BILBAO -------------------------------------\n",
      "----------------- Day 1 -----------------\n",
      "------- 12 -------\n",
      "METRICS:\n",
      "BENCENO\n",
      "R2: 0.0013288944684830889\n",
      "RMSE: 0.20060994917945604\n",
      "MAE: 0.14131894302368167\n",
      "SEM: 2.044091651218135\n",
      "AEM: 5.314714759450418\n",
      "AICBIC: -0.7278789653684704\n",
      "MAPE: 123.27201490150262\n",
      "CVRMSE: 205.75379403021134\n",
      "\n",
      "CO\n",
      "R2: 0.17761288387062363\n",
      "RMSE: 0.0719642167479495\n",
      "MAE: 0.05655689322948452\n",
      "SEM: 2.209837897822124\n",
      "AEM: 6.137520935460451\n",
      "AICBIC: -2.77826589644833\n",
      "MAPE: 20.49260031855835\n",
      "CVRMSE: 24.7441432944239\n",
      "\n",
      "CO 8H\n",
      "R2: 0.8748605878807415\n",
      "RMSE: 0.024195670720079623\n",
      "MAE: 0.01994856454432012\n",
      "SEM: 2.234515409459052\n",
      "AEM: 6.210051027772106\n",
      "AICBIC: -4.958256465587497\n",
      "MAPE: 6.382654030570754\n",
      "CVRMSE: 7.013237889878152\n",
      "\n",
      "ETILBENCENO\n",
      "R2: 0.8645161754177528\n",
      "RMSE: 0.08486822320836564\n",
      "MAE: 0.05271150062202167\n",
      "SEM: 1.8470726002120108\n",
      "AEM: 4.506092249320271\n",
      "AICBIC: -2.448404431551234\n",
      "MAPE: 7.774789701078094\n",
      "CVRMSE: 46.08229314481392\n",
      "\n",
      "NO\n",
      "R2: 0.5781328176208743\n",
      "RMSE: 3.0481039322436456\n",
      "MAE: 2.0104170984067022\n",
      "SEM: 1.999606529550456\n",
      "AEM: 5.182916827092682\n",
      "AICBIC: 4.713946121284384\n",
      "MAPE: 50.081641011376924\n",
      "CVRMSE: 62.718187906247856\n",
      "\n",
      "NO2\n",
      "R2: 0.33404368317716165\n",
      "RMSE: 9.233744122565907\n",
      "MAE: 5.262716877872751\n",
      "SEM: 1.7509385649290912\n",
      "AEM: 4.208643677640414\n",
      "AICBIC: 6.930635876476247\n",
      "MAPE: 29.194301134319957\n",
      "CVRMSE: 42.781826050498424\n",
      "\n",
      "NOX\n",
      "R2: 0.5232808988298627\n",
      "RMSE: 9.522573344752669\n",
      "MAE: 7.067042021577557\n",
      "SEM: 2.1442161018931483\n",
      "AEM: 5.822496409680188\n",
      "AICBIC: 6.992236892986101\n",
      "MAPE: 28.009894666723717\n",
      "CVRMSE: 32.836459809491956\n",
      "\n",
      "O3\n",
      "R2: 0.6102395789491586\n",
      "RMSE: 11.812006101473267\n",
      "MAE: 7.9037937444945205\n",
      "SEM: 2.0309127114799055\n",
      "AEM: 5.336273536010877\n",
      "AICBIC: 7.42313961064849\n",
      "MAPE: 14.012187230086273\n",
      "CVRMSE: 19.350726719137093\n",
      "\n",
      "O3 8H\n",
      "R2: 0.9619898896353755\n",
      "RMSE: 3.7493926418825128\n",
      "MAE: 2.88052828585108\n",
      "SEM: 2.1829510380031123\n",
      "AEM: 6.006318006982099\n",
      "AICBIC: 5.128094379188737\n",
      "MAPE: 6.34133350095795\n",
      "CVRMSE: 7.5113041239716445\n",
      "\n",
      "ORTOXILENO\n",
      "R2: 0.7539858107662079\n",
      "RMSE: 0.48606875681071193\n",
      "MAE: 0.3971971004369359\n",
      "SEM: 2.2405594572231493\n",
      "AEM: 6.275782415730489\n",
      "AICBIC: 1.042096269449769\n",
      "MAPE: 110.14389476547689\n",
      "CVRMSE: 54.51238394138825\n",
      "\n",
      "PM10\n",
      "R2: 0.8078363236990543\n",
      "RMSE: 2.735723043946312\n",
      "MAE: 2.3536766022443767\n",
      "SEM: 2.3085437103679842\n",
      "AEM: 6.673266152308017\n",
      "AICBIC: 4.497698185805467\n",
      "MAPE: 12.225516699053397\n",
      "CVRMSE: 13.45437562596547\n",
      "\n",
      "PM2.5\n",
      "R2: 0.7987228755816713\n",
      "RMSE: 1.865259021419249\n",
      "MAE: 1.4113388930360486\n",
      "SEM: 2.152612191167451\n",
      "AEM: 5.8346976371003505\n",
      "AICBIC: 3.7317065076511478\n",
      "MAPE: 12.125458626443107\n",
      "CVRMSE: 15.50613665190924\n",
      "\n",
      "SO2\n",
      "R2: 0.9544872470184977\n",
      "RMSE: 0.9111788466328028\n",
      "MAE: 0.7807460838059587\n",
      "SEM: 2.297878831810462\n",
      "AEM: 6.596678316946759\n",
      "AICBIC: 2.2988744858597827\n",
      "MAPE: 11.881725664848956\n",
      "CVRMSE: 12.763098120221352\n",
      "\n",
      "TOLUENO\n",
      "R2: 0.43547675601054897\n",
      "RMSE: 0.8885939004189236\n",
      "MAE: 0.6183369251839403\n",
      "SEM: 2.0641482042999755\n",
      "AEM: 5.472820308549901\n",
      "AICBIC: 2.2486767442610334\n",
      "MAPE: 88.8207647405204\n",
      "CVRMSE: 72.58765694368333\n",
      "\n",
      "DIRECWIND\n",
      "R2: 0.6379391675870806\n",
      "RMSE: 66.87216396379932\n",
      "MAE: 61.565759755174305\n",
      "SEM: 2.394748524785709\n",
      "AEM: 7.21413686286263\n",
      "AICBIC: 10.890472242385943\n",
      "MAPE: 29.71073278833502\n",
      "CVRMSE: 26.020297262178726\n",
      "\n",
      "HUMID\n",
      "R2: 0.9611203813850594\n",
      "RMSE: 5.072354910941198\n",
      "MAE: 4.119459722439449\n",
      "SEM: 2.2150456783245795\n",
      "AEM: 6.1082851666404885\n",
      "AICBIC: 5.732517028270945\n",
      "MAPE: 6.733515464084886\n",
      "CVRMSE: 8.898868264809119\n",
      "\n",
      "PRECIP\n",
      "R2: nan\n",
      "RMSE: 0.29111616423420916\n",
      "MAE: 0.25054771073861054\n",
      "SEM: 2.3045027104752287\n",
      "AEM: 6.636514995169797\n",
      "AICBIC: 0.016840846473161433\n",
      "MAPE: 25.054771073861055\n",
      "CVRMSE: inf\n",
      "\n",
      "TEMP\n",
      "R2: 0.9338784606479232\n",
      "RMSE: 2.299236308696768\n",
      "MAE: 1.9206373806049422\n",
      "SEM: 2.2712615004122947\n",
      "AEM: 6.4562398272440324\n",
      "AICBIC: 4.150060705989322\n",
      "MAPE: 7.9225975654456775\n",
      "CVRMSE: 8.600634571184917\n",
      "\n",
      "SPEEDWIND\n",
      "R2: 0.901852594816748\n",
      "RMSE: 0.5779807750422292\n",
      "MAE: 0.387584679491818\n",
      "SEM: 1.9982122317604847\n",
      "AEM: 5.137975834898245\n",
      "AICBIC: 1.3884773057169233\n",
      "MAPE: 48.66610117506829\n",
      "CVRMSE: 21.466324049850666\n",
      "\n",
      "CAR\n",
      "R2: 0.9412124010594213\n",
      "RMSE: 268.6065086550661\n",
      "MAE: 246.23968441784382\n",
      "SEM: 2.3849758157864933\n",
      "AEM: 7.142566946868927\n",
      "AICBIC: 13.671401680931348\n",
      "MAPE: 13.318669024404839\n",
      "CVRMSE: 13.664906324659967\n",
      "\n",
      "MOTORCYCLE\n",
      "R2: 0.0019185500109690837\n",
      "RMSE: 4.541573258880138\n",
      "MAE: 3.706646352385482\n",
      "SEM: 2.244201180990326\n",
      "AEM: 6.305462702643145\n",
      "AICBIC: 5.511453619423236\n",
      "MAPE: 70.52248295267275\n",
      "CVRMSE: 53.95928624412046\n",
      "\n",
      "BUS\n",
      "R2: 0.8813907604040384\n",
      "RMSE: 45.788326280695394\n",
      "MAE: 42.07766823321583\n",
      "SEM: 2.3732093705598905\n",
      "AEM: 7.036758051841895\n",
      "AICBIC: 10.13296499764908\n",
      "MAPE: 20.505138842376887\n",
      "CVRMSE: 22.417785204746828\n",
      "\n",
      "TRUCK\n",
      "R2: 0.7290921543498119\n",
      "RMSE: 55.44102643374858\n",
      "MAE: 32.96480293373268\n",
      "SEM: 1.902767492655582\n",
      "AEM: 4.876337700225279\n",
      "AICBIC: 10.51554638784303\n",
      "MAPE: 12.904054248189883\n",
      "CVRMSE: 19.930866303324834\n",
      "\n",
      "------- 24 -------\n",
      "METRICS:\n",
      "BENCENO\n",
      "R2: 0.14300319048489868\n",
      "RMSE: 0.17132998778001932\n",
      "MAE: 0.12089818455775582\n",
      "SEM: 2.7198105471156264\n",
      "AEM: 10.298238337501028\n",
      "AICBIC: -0.3502738275750354\n",
      "MAPE: 122.24725068885948\n",
      "CVRMSE: 146.33166216087062\n",
      "\n",
      "CO\n",
      "R2: 0.44717626033602376\n",
      "RMSE: 0.07775739530214522\n",
      "MAE: 0.06494712156491973\n",
      "SEM: 2.9746144172172437\n",
      "AEM: 13.387140213690097\n",
      "AICBIC: -1.9302694016915924\n",
      "MAPE: 19.254063314288018\n",
      "CVRMSE: 22.484066111463676\n",
      "\n",
      "CO 8H\n",
      "R2: 0.7711774394656598\n",
      "RMSE: 0.0324965754517161\n",
      "MAE: 0.027260405790060744\n",
      "SEM: 2.9467971106366395\n",
      "AEM: 12.93535307853787\n",
      "AICBIC: -3.675187301481568\n",
      "MAPE: 8.024647539104484\n",
      "CVRMSE: 9.26268183896896\n",
      "\n",
      "ETILBENCENO\n",
      "R2: 0.5873704717336036\n",
      "RMSE: 0.15893876806785992\n",
      "MAE: 0.09483378082374112\n",
      "SEM: 2.525919131575622\n",
      "AEM: 8.626676647461833\n",
      "AICBIC: -0.5004186845038563\n",
      "MAPE: 35.892470319911766\n",
      "CVRMSE: 63.68164329930948\n",
      "\n",
      "NO\n",
      "R2: 0.7309278900750853\n",
      "RMSE: 11.895251949325544\n",
      "MAE: 6.7056225521847\n",
      "SEM: 2.371856262280903\n",
      "AEM: 7.366808150365118\n",
      "AICBIC: 8.13033247963287\n",
      "MAPE: 77.71437331796888\n",
      "CVRMSE: 105.09333583059563\n",
      "\n",
      "NO2\n",
      "R2: 0.6579718227143458\n",
      "RMSE: 7.787117397839837\n",
      "MAE: 5.2508614537809075\n",
      "SEM: 2.7158584571196727\n",
      "AEM: 10.374131230794458\n",
      "AICBIC: 7.282995335574344\n",
      "MAPE: 23.399635261700254\n",
      "CVRMSE: 28.89289740092698\n",
      "\n",
      "NOX\n",
      "R2: 0.7798997816855266\n",
      "RMSE: 24.16863328984409\n",
      "MAE: 14.917617878265682\n",
      "SEM: 2.580282581565674\n",
      "AEM: 9.101237766178542\n",
      "AICBIC: 9.548165125132625\n",
      "MAPE: 31.271024225976806\n",
      "CVRMSE: 54.6096386601258\n",
      "\n",
      "O3\n",
      "R2: 0.758480093348349\n",
      "RMSE: 12.60920579493044\n",
      "MAE: 7.551767009807132\n",
      "SEM: 2.5262989142883168\n",
      "AEM: 8.629714978539253\n",
      "AICBIC: 8.246908162009614\n",
      "MAPE: 71.07142120101399\n",
      "CVRMSE: 32.19371692322666\n",
      "\n",
      "O3 8H\n",
      "R2: 0.9203685221811976\n",
      "RMSE: 6.406888429060525\n",
      "MAE: 4.86146774329245\n",
      "SEM: 2.8408187835817333\n",
      "AEM: 11.666131612625694\n",
      "AICBIC: 6.892801287532815\n",
      "MAPE: 13.761915832069912\n",
      "CVRMSE: 15.682337817180278\n",
      "\n",
      "ORTOXILENO\n",
      "R2: 0.5849293265823095\n",
      "RMSE: 0.6516956540477874\n",
      "MAE: 0.4384415598170212\n",
      "SEM: 2.6833414244031446\n",
      "AEM: 9.994081262743865\n",
      "AICBIC: 2.321698601737329\n",
      "MAPE: 69.82717580023638\n",
      "CVRMSE: 52.71552307767745\n",
      "\n",
      "PM10\n",
      "R2: 0.25502509354442554\n",
      "RMSE: 7.4177928342469945\n",
      "MAE: 4.947345016558964\n",
      "SEM: 2.6975229622723838\n",
      "AEM: 10.186443424788708\n",
      "AICBIC: 7.185816932821956\n",
      "MAPE: 18.23731644972492\n",
      "CVRMSE: 30.123016585774597\n",
      "\n",
      "PM2.5\n",
      "R2: 0.005450580144333869\n",
      "RMSE: 6.114650790392632\n",
      "MAE: 4.5577204892238\n",
      "SEM: 2.7846866330363604\n",
      "AEM: 10.95748703803029\n",
      "AICBIC: 6.799429151265984\n",
      "MAPE: 26.18392901931461\n",
      "CVRMSE: 40.09387983427768\n",
      "\n",
      "SO2\n",
      "R2: 0.7695090696589528\n",
      "RMSE: 1.550918046230686\n",
      "MAE: 1.2149993480369448\n",
      "SEM: 2.8834481572252493\n",
      "AEM: 12.18119951024804\n",
      "AICBIC: 4.055747917325298\n",
      "MAPE: 18.817940926765843\n",
      "CVRMSE: 23.168201860784553\n",
      "\n",
      "TOLUENO\n",
      "R2: 0.4157595833168451\n",
      "RMSE: 1.0510929011071701\n",
      "MAE: 0.7957113897751812\n",
      "SEM: 2.8612242563914454\n",
      "AEM: 11.95432635247096\n",
      "AICBIC: 3.2777147924468135\n",
      "MAPE: 62.84698858087309\n",
      "CVRMSE: 53.08550005591769\n",
      "\n",
      "DIRECWIND\n",
      "R2: 0.5139105948579756\n",
      "RMSE: 65.54814202780459\n",
      "MAE: 56.99643103828031\n",
      "SEM: 3.015555717172351\n",
      "AEM: 13.941885295844855\n",
      "AICBIC: 11.543623561262331\n",
      "MAPE: 28.389858047683664\n",
      "CVRMSE: 29.95915842063055\n",
      "\n",
      "HUMID\n",
      "R2: 0.9037884666469815\n",
      "RMSE: 10.337704815071392\n",
      "MAE: 8.66304355363051\n",
      "SEM: 2.9389741338170055\n",
      "AEM: 12.817489042414046\n",
      "AICBIC: 7.849649576303659\n",
      "MAPE: 11.406718728532047\n",
      "CVRMSE: 14.750589510208883\n",
      "\n",
      "PRECIP\n",
      "R2: nan\n",
      "RMSE: 0.35719790238737603\n",
      "MAE: 0.3130078139528633\n",
      "SEM: 3.0234579730536426\n",
      "AEM: 14.05345607800968\n",
      "AICBIC: 1.1191232256023405\n",
      "MAPE: 31.300781395286332\n",
      "CVRMSE: inf\n",
      "\n",
      "TEMP\n",
      "R2: 0.8807600242016308\n",
      "RMSE: 2.817448055502841\n",
      "MAE: 2.3190137791136887\n",
      "SEM: 2.914239929444398\n",
      "AEM: 12.497813102516412\n",
      "AICBIC: 5.249716891114108\n",
      "MAPE: 10.988274597727221\n",
      "CVRMSE: 12.294318787648761\n",
      "\n",
      "SPEEDWIND\n",
      "R2: 0.811732585676493\n",
      "RMSE: 0.5794523787838535\n",
      "MAE: 0.4296043789728234\n",
      "SEM: 2.8143110722602485\n",
      "AEM: 11.366663300879988\n",
      "AICBIC: 2.08671023841637\n",
      "MAPE: 39.386838325361204\n",
      "CVRMSE: 26.764544054681455\n",
      "\n",
      "CAR\n",
      "R2: 0.9249738662857037\n",
      "RMSE: 266.78454296556197\n",
      "MAE: 219.1123021898171\n",
      "SEM: 2.911130418167349\n",
      "AEM: 12.458657582382482\n",
      "AICBIC: 14.350936585250926\n",
      "MAPE: 13.108257029846152\n",
      "CVRMSE: 16.300481240258367\n",
      "\n",
      "MOTORCYCLE\n",
      "R2: 0.35899270568228864\n",
      "RMSE: 4.22837956039007\n",
      "MAE: 3.2092962238976424\n",
      "SEM: 2.834944232974904\n",
      "AEM: 11.583922961540054\n",
      "AICBIC: 6.061691504374309\n",
      "MAPE: 97.51823317582954\n",
      "CVRMSE: 73.53703583287079\n",
      "\n",
      "BUS\n",
      "R2: 0.9015209147800384\n",
      "RMSE: 43.45724931662566\n",
      "MAE: 36.27539053096748\n",
      "SEM: 2.932041462590559\n",
      "AEM: 12.72101492511196\n",
      "AICBIC: 10.721609191397677\n",
      "MAPE: 31.084864089505643\n",
      "CVRMSE: 28.75583081331723\n",
      "\n",
      "TRUCK\n",
      "R2: 0.8435862989481798\n",
      "RMSE: 61.90894401730262\n",
      "MAE: 44.25554395833365\n",
      "SEM: 2.801772031327866\n",
      "AEM: 11.308883212890924\n",
      "AICBIC: 11.429383151641748\n",
      "MAPE: 39.29200193716649\n",
      "CVRMSE: 30.260990965687647\n",
      "\n",
      "\n",
      "CPU times: user 16h 28min 48s, sys: 1h 20s, total: 17h 29min 8s\n",
      "Wall time: 1h 8min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Create real-forecasted dataset\n",
    "data_keys = [k for k in datasets.keys()]\n",
    "data_variables = list(set([item for sublist in multivariate_variables.values() for item in sublist]))\n",
    "data_timeseries = [\"12h\", \"24h\"]\n",
    "data_type = [\"Real\", \"Forecasted\"]\n",
    "max_steps = 0\n",
    "for sf_val in steps_to_forecast.values():\n",
    "    for v in sf_val:\n",
    "        if v > max_steps:\n",
    "            max_steps = v\n",
    "data_steps = [x for x in range(max_steps)]\n",
    "data_df = DataFrame([], \n",
    "    index=[f'Day {x}' for x in range(1, days_to_validate+1)], \n",
    "    columns=[\n",
    "        list(concatenate([([i]*len(data_variables)*len(data_timeseries)*len(data_type)*len(data_steps)) for i in data_keys], axis=0)),\n",
    "        len(data_keys)*list(concatenate([([i]*len(data_timeseries)*len(data_type)*len(data_steps)) for i in data_variables], axis=0)),\n",
    "        len(data_keys)*len(data_variables)*list(concatenate([([i]*len(data_type)*len(data_steps)) for i in data_timeseries], axis=0)),\n",
    "        len(data_keys)*len(data_variables)*len(data_timeseries)*list(concatenate([([i]*len(data_steps)) for i in data_type], axis=0)),\n",
    "        len(data_keys)*len(data_variables)*len(data_timeseries)*len(data_type)*[i for i in data_steps]\n",
    "    ])\n",
    "\n",
    "# Create a metrics dataframe\n",
    "#columns = [c for c in list(datasets[next(iter(datasets))].columns)]\n",
    "columns = list(set(col for dataset in datasets.values() for col in dataset.columns))\n",
    "days = [f'Day {x}' for x in range(1, days_to_validate+1)]\n",
    "timeseries = [\"12h\", \"24h\"]\n",
    "metrics = [x.upper() for x in available_metrics.keys()]\n",
    "metrics_df = DataFrame([], \n",
    "       index=[k.upper() for k in datasets.keys()], \n",
    "       columns=[\n",
    "           list(concatenate([([i]*len(days)*len(timeseries)*len(metrics)) for i in columns], axis=0)),\n",
    "           len(columns)*list(concatenate([([i]*len(timeseries)*len(metrics)) for i in days], axis=0)),\n",
    "           len(columns)*len(days)*list(concatenate([([i]*len(metrics)) for i in timeseries], axis=0)),\n",
    "           len(columns)*len(days)*len(timeseries)*[metric for metric in metrics]\n",
    "       ])\n",
    "\n",
    "# Iterate over all possible train datasets\n",
    "for key, dataset in datasets.items():\n",
    "\n",
    "    # Print a header\n",
    "    print('-' * 37, key.upper(), '-' * 37)\n",
    "\n",
    "    # Dataset normalization\n",
    "    normalized_dataset = dataset.copy()\n",
    "    for column in dataset.columns:\n",
    "        normalized_dataset[column] = min_max_scaler(\n",
    "            normalized_dataset[column].values,\n",
    "            min_limit=normalization_parameters[column]['min_limit']\n",
    "            if 'min_limit' in normalization_parameters[column].keys() else None,\n",
    "            max_limit=normalization_parameters[column]['max_limit']\n",
    "            if 'max_limit' in normalization_parameters[column].keys() else None,\n",
    "            min_range=normalization_parameters[column]['min_range']\n",
    "            if 'min_range' in normalization_parameters[column].keys() else 0,\n",
    "            max_range=normalization_parameters[column]['max_range']\n",
    "            if 'max_range' in normalization_parameters[column].keys() else 1)\n",
    "\n",
    "    # Dataset vectorization\n",
    "    reframed_dataset = create_multivariate_timeseries_dataset(normalized_dataset.values, normalized_dataset.columns, look_back[key], 1)\n",
    "    reframed_dataset = reframed_dataset.values\n",
    "    n_features = len(normalized_dataset.columns)\n",
    "    n_obs = look_back[key] * n_features\n",
    "    subsequences = 1\n",
    "    look_back_per_sequence = look_back[key] // subsequences\n",
    "    X_train, y_train = reframed_dataset[:-validation_sizes[key]-days_to_validate*test_sizes[key], :n_obs], reframed_dataset[:-validation_sizes[key]-days_to_validate*test_sizes[key], -n_features:]\n",
    "    X_validation, y_validation = reframed_dataset[-validation_sizes[key]-days_to_validate*test_sizes[key]:-days_to_validate*test_sizes[key], :n_obs], reframed_dataset[-validation_sizes[key]-days_to_validate*test_sizes[key]:-days_to_validate*test_sizes[key], -n_features:]\n",
    "    X_test, y_test = reframed_dataset[-days_to_validate*test_sizes[key]:, :n_obs], reframed_dataset[-days_to_validate*test_sizes[key]:, -n_features:]\n",
    "    \n",
    "    # Dataset normalization\n",
    "    normalized_dataset = globals()[f'synth_datasets'][key].copy()\n",
    "    for column in dataset.columns:\n",
    "        normalized_dataset[column] = min_max_scaler(\n",
    "            normalized_dataset[column].values,\n",
    "            min_limit=normalization_parameters[column]['min_limit']\n",
    "            if 'min_limit' in normalization_parameters[column].keys() else None,\n",
    "            max_limit=normalization_parameters[column]['max_limit']\n",
    "            if 'max_limit' in normalization_parameters[column].keys() else None,\n",
    "            min_range=normalization_parameters[column]['min_range']\n",
    "            if 'min_range' in normalization_parameters[column].keys() else 0,\n",
    "            max_range=normalization_parameters[column]['max_range']\n",
    "            if 'max_range' in normalization_parameters[column].keys() else 1)\n",
    "\n",
    "    # Dataset vectorization\n",
    "    reframed_dataset = create_multivariate_timeseries_dataset(normalized_dataset.values, normalized_dataset.columns, look_back[key], 1)\n",
    "    reframed_dataset = reframed_dataset.values\n",
    "    n_features = len(normalized_dataset.columns)\n",
    "    n_obs = look_back[key] * n_features\n",
    "    subsequences = 1\n",
    "    look_back_per_sequence = look_back[key] // subsequences\n",
    "    X_train, y_train = reframed_dataset[:-days_to_validate*validation_sizes[key], :n_obs], reframed_dataset[:-days_to_validate*validation_sizes[key], -n_features:]\n",
    "    #X_validation, y_validation = reframed_dataset[-days_to_validate*validation_sizes[key]:, :n_obs], reframed_dataset[-days_to_validate*validation_sizes[key]:, -n_features:]\n",
    "    \n",
    "    # Create the model\n",
    "    model = Sequential()\n",
    "    model.add(TimeDistributed(Conv1D( \n",
    "        **model_parameters['cnn_model'],\n",
    "        input_shape=(None, look_back_per_sequence, n_features))))\n",
    "    model.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model.add(TimeDistributed(Flatten()))\n",
    "    model.add(LSTM(\n",
    "        **model_parameters['lstm_model']))\n",
    "    model.add(Dense(n_features))\n",
    "    model.compile(**model_parameters['compile'])\n",
    "    for name, value in model_parameters['backend'].items():\n",
    "        K.set_value(getattr(model.optimizer, name), value)\n",
    "\n",
    "    # Fit the model\n",
    "    cb_loss_history = LossHistory()\n",
    "    cb_early_stopping = EarlyStopping(monitor='val_loss', mode='min', min_delta=0, patience=300, restore_best_weights=True)\n",
    "    cb_reduce_learning_rate_on_plateau = ReduceLROnPlateauRestoreBestWeights(monitor='val_loss', mode='min', factor=0.5, patience=10, min_delta=0, min_lr=0.0001)\n",
    "    history = model.fit(\n",
    "        X_train.reshape(\n",
    "            X_train.shape[0],\n",
    "            subsequences,\n",
    "            look_back_per_sequence,\n",
    "            n_features),\n",
    "        y_train,\n",
    "        **model_parameters['fit'],\n",
    "        validation_data=(X_validation.reshape(\n",
    "            X_validation.shape[0],\n",
    "            subsequences,\n",
    "            look_back_per_sequence,\n",
    "            n_features), y_validation),\n",
    "        shuffle=False,\n",
    "        callbacks=[cb_loss_history, cb_early_stopping, cb_reduce_learning_rate_on_plateau])\n",
    "    history.history['loss_history_learning_rate'] = cb_loss_history.lr\n",
    "    history.history['early_stopped_epoch'] = cb_early_stopping.stopped_epoch\n",
    "    \n",
    "    # Check there is a test type\n",
    "    if test_type is not None:\n",
    "\n",
    "        # Dataset normalization\n",
    "        normalized_dataset = dataset.copy()\n",
    "        for column in dataset.columns:\n",
    "            normalized_dataset[column] = min_max_scaler(\n",
    "                normalized_dataset[column].values,\n",
    "                min_limit=normalization_parameters[column]['min_limit']\n",
    "                if 'min_limit' in normalization_parameters[column].keys() else None,\n",
    "                max_limit=normalization_parameters[column]['max_limit']\n",
    "                if 'max_limit' in normalization_parameters[column].keys() else None,\n",
    "                min_range=normalization_parameters[column]['min_range']\n",
    "                if 'min_range' in normalization_parameters[column].keys() else 0,\n",
    "                max_range=normalization_parameters[column]['max_range']\n",
    "                if 'max_range' in normalization_parameters[column].keys() else 1)\n",
    "\n",
    "        # Dataset vectorization\n",
    "        reframed_dataset = create_multivariate_timeseries_dataset(normalized_dataset.values, normalized_dataset.columns, look_back[key], 1)\n",
    "        reframed_dataset = reframed_dataset.values\n",
    "        n_features = len(normalized_dataset.columns)\n",
    "        n_obs = look_back[key] * n_features\n",
    "        subsequences = 1\n",
    "        look_back_per_sequence = look_back[key] // subsequences\n",
    "        X_train, y_train = reframed_dataset[:-days_to_validate*validation_sizes[key], :n_obs], reframed_dataset[:-days_to_validate*validation_sizes[key], -n_features:]\n",
    "        #X_validation, y_validation = reframed_dataset[-days_to_validate*validation_sizes[key]:, :n_obs], reframed_dataset[-days_to_validate*validation_sizes[key]:, -n_features:]\n",
    "        \n",
    "        # Fit the model\n",
    "        cb_loss_history = LossHistory()\n",
    "        cb_early_stopping = EarlyStopping(monitor='val_loss', mode='min', min_delta=0, patience=300, restore_best_weights=True)\n",
    "        cb_reduce_learning_rate_on_plateau = ReduceLROnPlateauRestoreBestWeights(monitor='val_loss', mode='min', factor=0.5, patience=10, min_delta=0, min_lr=0.0001)\n",
    "        history = model.fit(\n",
    "            X_train.reshape(\n",
    "                X_train.shape[0],\n",
    "                subsequences,\n",
    "                look_back_per_sequence,\n",
    "                n_features),\n",
    "            y_train,\n",
    "            **model_parameters['fit'],\n",
    "            validation_data=(X_validation.reshape(\n",
    "                X_validation.shape[0],\n",
    "                subsequences,\n",
    "                look_back_per_sequence,\n",
    "                n_features), y_validation),\n",
    "            shuffle=False,\n",
    "            callbacks=[cb_loss_history, cb_early_stopping, cb_reduce_learning_rate_on_plateau])\n",
    "        history.history['loss_history_learning_rate'] = cb_loss_history.lr\n",
    "        history.history['early_stopped_epoch'] = cb_early_stopping.stopped_epoch\n",
    "\n",
    "    # Check and create a directory if not exists\n",
    "    Path('./out/models/').mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    # Save the model\n",
    "    model.save(f'./out/models/CNNLSTM{\"\" if test_type is None else f\"_{test_type}\"}_{key}.h5')\n",
    "\n",
    "    # Check and create a directory if not exists\n",
    "    Path('./out/history/').mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "    # Save the history\n",
    "    with open(f'./out/history/CNNLSTM{\"\" if test_type is None else f\"_{test_type}\"}_{key}.bin', 'wb') as file:\n",
    "        dump(history.history, file)\n",
    "\n",
    "    # Denormalize validation data\n",
    "    denormalized_y_validation = y_test.copy()\n",
    "    for index, column in enumerate(dataset.columns):\n",
    "        denormalized_y_validation[:, index] = min_max_inverse_scaler(\n",
    "            denormalized_y_validation[:, index],\n",
    "            min_limit=normalization_parameters[column]['min_limit']\n",
    "            if 'min_limit' in normalization_parameters[column].keys() else None,\n",
    "            max_limit=normalization_parameters[column]['max_limit']\n",
    "            if 'max_limit' in normalization_parameters[column].keys() else None,\n",
    "            min_range=normalization_parameters[column]['min_range']\n",
    "            if 'min_range' in normalization_parameters[column].keys() else 0,\n",
    "            max_range=normalization_parameters[column]['max_range']\n",
    "            if 'max_range' in normalization_parameters[column].keys() else 1)\n",
    "\n",
    "    # For each day to forecast\n",
    "    for day in range(days_to_validate):\n",
    "\n",
    "        # Print a header\n",
    "        print('-' * 17, 'Day', str(day+1), '-' * 17)\n",
    "\n",
    "        # For each time steps to forecast\n",
    "        for steps in steps_to_forecast[key]:\n",
    "\n",
    "            # Print a header\n",
    "            print('-' * 7, str(steps), '-' * 7)\n",
    "\n",
    "            # Forecast with the model\n",
    "            model_history = asarray(X_test[0]).reshape(1, -1).copy()\n",
    "            model_predictions = asarray([])\n",
    "            for _ in range(steps):\n",
    "                _model_prediction = model.predict(\n",
    "                    model_history.reshape(\n",
    "                        model_history.shape[0],\n",
    "                        subsequences,\n",
    "                        look_back_per_sequence,\n",
    "                        n_features),\n",
    "                    **model_parameters['predict'])\n",
    "                for feature in _model_prediction[0]:\n",
    "                    model_history = update_fixed_size_array(model_history, [[feature]], axis=1)\n",
    "                model_predictions = append(model_predictions, _model_prediction[0])\n",
    "            model_predictions = model_predictions.reshape(-1, n_features)\n",
    "\n",
    "            # Denormalize forecast\n",
    "            denormalized_model_predictions = model_predictions.copy()\n",
    "            for index, column in enumerate(dataset.columns):\n",
    "                denormalized_model_predictions[:, index] = min_max_inverse_scaler(\n",
    "                    denormalized_model_predictions[:, index],\n",
    "                    min_limit=normalization_parameters[column]['min_limit']\n",
    "                    if 'min_limit' in normalization_parameters[column].keys() else None,\n",
    "                    max_limit=normalization_parameters[column]['max_limit']\n",
    "                    if 'max_limit' in normalization_parameters[column].keys() else None,\n",
    "                    min_range=normalization_parameters[column]['min_range']\n",
    "                    if 'min_range' in normalization_parameters[column].keys() else 0,\n",
    "                    max_range=normalization_parameters[column]['max_range']\n",
    "                    if 'max_range' in normalization_parameters[column].keys() else 1)\n",
    "\n",
    "            # Store real and forecasted data\n",
    "            for index, column in enumerate(dataset.columns):\n",
    "                for step in range(steps):\n",
    "                    data_df.loc[f'Day {day+1}'][key, column, str(int(int(steps)*int(''.join(filter(str.isdigit, key)))/60))+\"h\", 'Real', step] = denormalized_y_validation[step][index]\n",
    "                    data_df.loc[f'Day {day+1}'][key, column, str(int(int(steps)*int(''.join(filter(str.isdigit, key)))/60))+\"h\", 'Forecasted', step] = denormalized_model_predictions[step][index]\n",
    "\n",
    "            # Print the real data\n",
    "            #print('REAL DATA:')\n",
    "            #print(denormalized_y_validation[:steps, :])\n",
    "            #print()\n",
    "\n",
    "            # Print the forecasting\n",
    "            #print('PREDICTIONS:')\n",
    "            #print(denormalized_model_predictions)\n",
    "            #print()\n",
    "\n",
    "            # Metrics\n",
    "            #print('METRICS (NORMALIZED):')\n",
    "            #for index, column in enumerate(dataset.columns):\n",
    "            #    print(column.upper())\n",
    "            #    for mk, mf in available_metrics.items():\n",
    "            #        print(f'{mk.upper()}: {mf(y_validation[:steps, index], model_predictions[:, index])}')\n",
    "            #    print()\n",
    "            print('METRICS:')\n",
    "            for index, column in enumerate(dataset.columns):\n",
    "                print(column.upper())\n",
    "                for mk, mf in available_metrics.items():\n",
    "                    print(f'{mk.upper()}: {mf(denormalized_y_validation[day*steps:day*steps+steps, index], denormalized_model_predictions[:, index])}')\n",
    "                print()\n",
    "\n",
    "            # Save the metrics\n",
    "            for index, column in enumerate(dataset.columns):\n",
    "                for mk, mf in available_metrics.items():\n",
    "                    metrics_df.loc[key.upper()][column, f'Day {day+1}', str(int(int(steps)*int(''.join(filter(str.isdigit, key)))/60))+\"h\", mk.upper()] = mf(denormalized_y_validation[day*steps:day*steps+steps, index], denormalized_model_predictions[:, index])\n",
    "\n",
    "            \"\"\"\n",
    "            # Check and create a directory if not exists\n",
    "            Path('./out/metrics/').mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "            # Save the metrics\n",
    "            for index, column in enumerate(dataset.columns):\n",
    "                with open(f'./out/metrics/CNNLSTM_{key}_{str(steps)}_{column.upper()}.txt', 'a') as file:\n",
    "                    for mk, mf in available_metrics.items():\n",
    "                        file.write(f'{mf(denormalized_y_validation[day*steps:day*steps+steps, index], denormalized_model_predictions[:, index])};')\n",
    "                    file.write(f'\\n')\n",
    "            \"\"\"\n",
    "\n",
    "# Check and create a directory if not exists\n",
    "Path('./out/data/').mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "# Store the data\n",
    "data_df.to_csv(f\"./out/data/CNNLSTM_data{'' if test_type is None else f'_{test_type}'}.csv\", sep=\";\", index=True, decimal=\".\")\n",
    "\n",
    "# Check and create a directory if not exists\n",
    "Path('./out/metrics/').mkdir(parents = True, exist_ok = True)\n",
    "\n",
    "# Store the metrics\n",
    "metrics_df.to_csv(f\"./out/metrics/CNNLSTM_metrics{'' if test_type is None else f'_{test_type}'}.csv\", sep=\";\", index=True, decimal=\".\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
